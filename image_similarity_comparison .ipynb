{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Img2Vec():\n",
    "\n",
    "    def __init__(self, cuda=False, model='resnet-18', layer='default', layer_output_size=512):\n",
    "        \"\"\" Img2Vec\n",
    "        :param cuda: If set to True, will run forward pass on GPU\n",
    "        :param model: String name of requested model\n",
    "        :param layer: String or Int depending on model.  See more docs: https://github.com/christiansafka/img2vec.git\n",
    "        :param layer_output_size: Int depicting the output size of the requested layer\n",
    "        \"\"\"\n",
    "        self.device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "        self.layer_output_size = layer_output_size\n",
    "        self.model_name = model\n",
    "        \n",
    "        self.model, self.extraction_layer = self._get_model_and_layer(model, layer)\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        self.scaler = transforms.Resize((224, 224))\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    def get_vec(self, img, tensor=False):\n",
    "        \"\"\" Get vector embedding from PIL image\n",
    "        :param img: PIL Image or list of PIL Images\n",
    "        :param tensor: If True, get_vec will return a FloatTensor instead of Numpy array\n",
    "        :returns: Numpy ndarray\n",
    "        \"\"\"\n",
    "        if type(img) == list:\n",
    "            a = [self.normalize(self.to_tensor(self.scaler(im))) for im in img]\n",
    "            images = torch.stack(a).to(self.device) \n",
    "            if self.model_name == 'alexnet':\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(len(img), self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            h_x = self.model(images)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name == 'alexnet':\n",
    "                    return my_embedding.numpy()[:, :]\n",
    "                else:\n",
    "                    print(my_embedding.numpy()[:, :, 0, 0].shape)\n",
    "                    return my_embedding.numpy()[:, :, 0, 0]\n",
    "        else:\n",
    "            image = self.normalize(self.to_tensor(self.scaler(img))).unsqueeze(0).to(self.device)\n",
    "\n",
    "            if self.model_name == 'alexnet':\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size)\n",
    "            else:\n",
    "                my_embedding = torch.zeros(1, self.layer_output_size, 1, 1)\n",
    "\n",
    "            def copy_data(m, i, o):\n",
    "                my_embedding.copy_(o.data)\n",
    "\n",
    "            h = self.extraction_layer.register_forward_hook(copy_data)\n",
    "            h_x = self.model(image)\n",
    "            h.remove()\n",
    "\n",
    "            if tensor:\n",
    "                return my_embedding\n",
    "            else:\n",
    "                if self.model_name == 'alexnet':\n",
    "                    return my_embedding.numpy()[0, :]\n",
    "                else:\n",
    "                    return my_embedding.numpy()[0, :, 0, 0]\n",
    "\n",
    "    def _get_model_and_layer(self, model_name, layer):\n",
    "        \"\"\" Internal method for getting layer from model\n",
    "        :param model_name: model name such as 'resnet-18'\n",
    "        :param layer: layer as a string for resnet-18 or int for alexnet\n",
    "        :returns: pytorch model, selected layer\n",
    "        \"\"\"\n",
    "        if model_name == 'resnet-18':\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = 512\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'alexnet':\n",
    "            model = models.alexnet(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = 4096\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        else:\n",
    "            raise KeyError('Model %s was not found' % model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which filename would you like similarities for?\n",
      "t3.jpeg\n",
      "0.7850337 t4.jpg\n",
      "0.76756144 t5.jpg\n",
      "0.73189676 t2.jpeg\n",
      "0.73189676 t1.jpeg\n",
      "Which filename would you like similarities for?\n",
      "exit\n",
      "Could not find filename 'exit'\n"
     ]
    }
   ],
   "source": [
    "input_path = './test_images'\n",
    "\n",
    "img2vec = Img2Vec()\n",
    "\n",
    "# For each test image, we store the filename and vector as key, value in a dictionary\n",
    "pics = {}\n",
    "for file in os.listdir(input_path):\n",
    "    filename = os.fsdecode(file)\n",
    "    img = Image.open(os.path.join(input_path, filename))\n",
    "    vec = img2vec.get_vec(img)\n",
    "    pics[filename] = vec\n",
    "\n",
    "pic_name = \"\"\n",
    "while pic_name != \"exit\":\n",
    "    pic_name = str(input(\"Which filename would you like similarities for?\\n\"))\n",
    "\n",
    "    try:\n",
    "        sims = {}\n",
    "        for key in list(pics.keys()):\n",
    "            if key == pic_name:\n",
    "                continue\n",
    "\n",
    "            sims[key] = cosine_similarity(pics[pic_name].reshape((1, -1)), pics[key].reshape((1, -1)))[0][0]\n",
    "\n",
    "        d_view = [(v, k) for k, v in sims.items()]\n",
    "        d_view.sort(reverse=True)\n",
    "        for v, k in d_view:\n",
    "            print(v, k)\n",
    "\n",
    "    except KeyError as e:\n",
    "        print('Could not find filename %s' % e)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AntonioEnv] *",
   "language": "python",
   "name": "conda-env-AntonioEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
